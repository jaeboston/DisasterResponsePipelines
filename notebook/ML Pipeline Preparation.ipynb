{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "ML Pipeline Preparation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5rREnrMBljZ",
        "colab_type": "text"
      },
      "source": [
        "# ML Pipeline Preparation\n",
        "Follow the instructions below to help you create your ML pipeline.\n",
        "### 1. Import libraries and load data from database.\n",
        "- Import Python libraries\n",
        "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
        "- Define feature and target variables X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JL7sCGcBljb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d9f4c074-e20e-4488-9fc7-20c407632ec0"
      },
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine\n",
        "import nltk\n",
        "nltk.download(['punkt', 'wordnet'])\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bKken2qBljg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "engine = create_engine('sqlite:///disaster_message.db')\n",
        "df = pd.read_sql_table('tbl_disaster_message', 'sqlite:///disaster_message.db')  \n",
        "X = df.loc[:,'message'] \n",
        "Y = df.iloc[:, 4:] "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3UD8cbhBljl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "766a371e-9a88-4c51-9cd3-61d4841c5f83"
      },
      "source": [
        "Y.related.value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    20093\n",
              "0     6122\n",
              "Name: related, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmDW7TqeBljp",
        "colab_type": "text"
      },
      "source": [
        "### 2. Write a tokenization function to process your text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE7C6j62Bljq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    \n",
        "    #: tokenize text\n",
        "    tokens= word_tokenize(text)\n",
        "    \n",
        "    #: initiate Lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    \n",
        "    #: iterate through each token\n",
        "    clean_tokens = []\n",
        "    for tok in tokens:\n",
        "        \n",
        "        #: Lemmatize, normalize case, and remove Leading/trailing wite space\n",
        "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
        "        clean_tokens.append(clean_tok)\n",
        "    \n",
        "    return clean_tokens\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-37CULAqBljs",
        "colab_type": "text"
      },
      "source": [
        "### 3. Build a machine learning pipeline\n",
        "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p35iXkAABljt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vector', CountVectorizer(tokenizer=tokenize)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_EapN0PBljv",
        "colab_type": "text"
      },
      "source": [
        "### 4. Train pipeline\n",
        "- Split data into train and test sets\n",
        "- Train pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7NmFOFBBljv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "86123e5b-93b9-468e-867d-f3c9a2de876f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vector',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenize...\n",
              "                                                                        ccp_alpha=0.0,\n",
              "                                                                        class_weight=None,\n",
              "                                                                        criterion='gini',\n",
              "                                                                        max_depth=None,\n",
              "                                                                        max_features='auto',\n",
              "                                                                        max_leaf_nodes=None,\n",
              "                                                                        max_samples=None,\n",
              "                                                                        min_impurity_decrease=0.0,\n",
              "                                                                        min_impurity_split=None,\n",
              "                                                                        min_samples_leaf=1,\n",
              "                                                                        min_samples_split=2,\n",
              "                                                                        min_weight_fraction_leaf=0.0,\n",
              "                                                                        n_estimators=100,\n",
              "                                                                        n_jobs=None,\n",
              "                                                                        oob_score=False,\n",
              "                                                                        random_state=None,\n",
              "                                                                        verbose=0,\n",
              "                                                                        warm_start=False),\n",
              "                                       n_jobs=None))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BUljRCrBljy",
        "colab_type": "text"
      },
      "source": [
        "### 5. Test your model\n",
        "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSvZxnNtBljy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = pipeline.predict(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIuAdFkPBlj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "e05f3563-f7a8-44f2-be6f-272390d64c58"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test.values, y_predict, target_names=Y.columns.values))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "               related       0.81      0.97      0.88      4999\n",
            "               request       0.87      0.42      0.57      1093\n",
            "                 offer       0.00      0.00      0.00        38\n",
            "           aid_related       0.78      0.60      0.68      2708\n",
            "          medical_help       0.66      0.04      0.07       506\n",
            "      medical_products       0.75      0.07      0.13       333\n",
            "     search_and_rescue       0.86      0.03      0.06       185\n",
            "              security       0.00      0.00      0.00       119\n",
            "              military       1.00      0.03      0.05       227\n",
            "           child_alone       0.00      0.00      0.00         0\n",
            "                 water       0.95      0.24      0.38       390\n",
            "                  food       0.87      0.36      0.51       744\n",
            "               shelter       0.90      0.21      0.35       596\n",
            "              clothing       0.67      0.02      0.04        86\n",
            "                 money       0.40      0.01      0.02       163\n",
            "        missing_people       0.00      0.00      0.00        69\n",
            "              refugees       1.00      0.00      0.01       207\n",
            "                 death       0.93      0.13      0.23       283\n",
            "             other_aid       0.65      0.02      0.03       870\n",
            "infrastructure_related       0.20      0.00      0.00       422\n",
            "             transport       0.68      0.05      0.09       303\n",
            "             buildings       0.81      0.06      0.12       336\n",
            "           electricity       1.00      0.01      0.02       130\n",
            "                 tools       0.00      0.00      0.00        33\n",
            "             hospitals       0.00      0.00      0.00        78\n",
            "                 shops       0.00      0.00      0.00        28\n",
            "           aid_centers       0.00      0.00      0.00        81\n",
            "  other_infrastructure       0.00      0.00      0.00       283\n",
            "       weather_related       0.88      0.61      0.72      1844\n",
            "                floods       0.91      0.27      0.41       550\n",
            "                 storm       0.79      0.43      0.55       605\n",
            "                  fire       0.00      0.00      0.00        64\n",
            "            earthquake       0.92      0.73      0.81       645\n",
            "                  cold       1.00      0.06      0.11       143\n",
            "         other_weather       0.57      0.01      0.02       338\n",
            "         direct_report       0.84      0.33      0.47      1256\n",
            "\n",
            "             micro avg       0.82      0.48      0.61     20755\n",
            "             macro avg       0.57      0.16      0.20     20755\n",
            "          weighted avg       0.77      0.48      0.53     20755\n",
            "           samples avg       0.70      0.46      0.51     20755\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bWIia1aBlj3",
        "colab_type": "text"
      },
      "source": [
        "### 6. Improve your model\n",
        "Use grid search to find better parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfJSzfmJBlj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d52ea40-b182-445c-a0a3-5dfc4ad3851d"
      },
      "source": [
        "pipeline.get_params()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                        ccp_alpha=0.0,\n",
              "                                                        class_weight=None,\n",
              "                                                        criterion='gini',\n",
              "                                                        max_depth=None,\n",
              "                                                        max_features='auto',\n",
              "                                                        max_leaf_nodes=None,\n",
              "                                                        max_samples=None,\n",
              "                                                        min_impurity_decrease=0.0,\n",
              "                                                        min_impurity_split=None,\n",
              "                                                        min_samples_leaf=1,\n",
              "                                                        min_samples_split=2,\n",
              "                                                        min_weight_fraction_leaf=0.0,\n",
              "                                                        n_estimators=100,\n",
              "                                                        n_jobs=None,\n",
              "                                                        oob_score=False,\n",
              "                                                        random_state=None,\n",
              "                                                        verbose=0,\n",
              "                                                        warm_start=False),\n",
              "                       n_jobs=None),\n",
              " 'clf__estimator': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                        n_jobs=None, oob_score=False, random_state=None,\n",
              "                        verbose=0, warm_start=False),\n",
              " 'clf__estimator__bootstrap': True,\n",
              " 'clf__estimator__ccp_alpha': 0.0,\n",
              " 'clf__estimator__class_weight': None,\n",
              " 'clf__estimator__criterion': 'gini',\n",
              " 'clf__estimator__max_depth': None,\n",
              " 'clf__estimator__max_features': 'auto',\n",
              " 'clf__estimator__max_leaf_nodes': None,\n",
              " 'clf__estimator__max_samples': None,\n",
              " 'clf__estimator__min_impurity_decrease': 0.0,\n",
              " 'clf__estimator__min_impurity_split': None,\n",
              " 'clf__estimator__min_samples_leaf': 1,\n",
              " 'clf__estimator__min_samples_split': 2,\n",
              " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
              " 'clf__estimator__n_estimators': 100,\n",
              " 'clf__estimator__n_jobs': None,\n",
              " 'clf__estimator__oob_score': False,\n",
              " 'clf__estimator__random_state': None,\n",
              " 'clf__estimator__verbose': 0,\n",
              " 'clf__estimator__warm_start': False,\n",
              " 'clf__n_jobs': None,\n",
              " 'memory': None,\n",
              " 'steps': [('vector',\n",
              "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                   tokenizer=<function tokenize at 0x7f21365e0048>,\n",
              "                   vocabulary=None)),\n",
              "  ('tfidf',\n",
              "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
              "  ('clf',\n",
              "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                          ccp_alpha=0.0,\n",
              "                                                          class_weight=None,\n",
              "                                                          criterion='gini',\n",
              "                                                          max_depth=None,\n",
              "                                                          max_features='auto',\n",
              "                                                          max_leaf_nodes=None,\n",
              "                                                          max_samples=None,\n",
              "                                                          min_impurity_decrease=0.0,\n",
              "                                                          min_impurity_split=None,\n",
              "                                                          min_samples_leaf=1,\n",
              "                                                          min_samples_split=2,\n",
              "                                                          min_weight_fraction_leaf=0.0,\n",
              "                                                          n_estimators=100,\n",
              "                                                          n_jobs=None,\n",
              "                                                          oob_score=False,\n",
              "                                                          random_state=None,\n",
              "                                                          verbose=0,\n",
              "                                                          warm_start=False),\n",
              "                         n_jobs=None))],\n",
              " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
              " 'tfidf__norm': 'l2',\n",
              " 'tfidf__smooth_idf': True,\n",
              " 'tfidf__sublinear_tf': False,\n",
              " 'tfidf__use_idf': True,\n",
              " 'vector': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                 tokenizer=<function tokenize at 0x7f21365e0048>,\n",
              "                 vocabulary=None),\n",
              " 'vector__analyzer': 'word',\n",
              " 'vector__binary': False,\n",
              " 'vector__decode_error': 'strict',\n",
              " 'vector__dtype': numpy.int64,\n",
              " 'vector__encoding': 'utf-8',\n",
              " 'vector__input': 'content',\n",
              " 'vector__lowercase': True,\n",
              " 'vector__max_df': 1.0,\n",
              " 'vector__max_features': None,\n",
              " 'vector__min_df': 1,\n",
              " 'vector__ngram_range': (1, 1),\n",
              " 'vector__preprocessor': None,\n",
              " 'vector__stop_words': None,\n",
              " 'vector__strip_accents': None,\n",
              " 'vector__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'vector__tokenizer': <function __main__.tokenize>,\n",
              " 'vector__vocabulary': None,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewOpUTf6Blj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters ={\n",
        "        'clf__estimator__n_estimators': [10, 50]\n",
        "        #'clf__estimator__min_samples_split': [2, 10],\n",
        "        #'clf__estimator__min_samples_leaf': [1, 4]\n",
        "        #'clf__estimator__max_depth': [20, None]\n",
        "    }\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEtDKIYaBlj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=3, n_jobs = -1, verbose = 3)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsMg_FEvBlkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "c795f2cf-0cdb-48e6-c805-d45aa0e5232d"
      },
      "source": [
        "cv.fit(X_train, y_train)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  6.2min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  6.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vector',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preprocessor=None,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_accents=None,\n",
              "                                                        token_pattern='(?...\n",
              "                                                                                               min_samples_leaf=1,\n",
              "                                                                                               min_samples_split=2,\n",
              "                                                                                               min_weight_fraction_leaf=0.0,\n",
              "                                                                                               n_estimators=100,\n",
              "                                                                                               n_jobs=None,\n",
              "                                                                                               oob_score=False,\n",
              "                                                                                               random_state=None,\n",
              "                                                                                               verbose=0,\n",
              "                                                                                               warm_start=False),\n",
              "                                                              n_jobs=None))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__estimator__n_estimators': [10, 50]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFujMUjih66k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a7cfc71-9209-4b57-ef42-f8705a25d317"
      },
      "source": [
        "improved_model = cv.best_params_\n",
        "improved_model"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__estimator__n_estimators': 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7Vpa3gWBlkC",
        "colab_type": "text"
      },
      "source": [
        "### 7. Test your model\n",
        "Show the accuracy, precision, and recall of the tuned model.  \n",
        "\n",
        "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRaC6Ux6BlkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = cv.predict(X_test)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjO6L59fBlkE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "82f2c11a-ef51-4cfc-ae3a-88af5a03cc41"
      },
      "source": [
        "print(classification_report(y_test.values, y_predict, target_names=Y.columns.values))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "               related       0.81      0.97      0.88      4999\n",
            "               request       0.87      0.43      0.57      1093\n",
            "                 offer       0.00      0.00      0.00        38\n",
            "           aid_related       0.79      0.58      0.67      2708\n",
            "          medical_help       0.60      0.03      0.06       506\n",
            "      medical_products       0.86      0.08      0.14       333\n",
            "     search_and_rescue       0.67      0.02      0.04       185\n",
            "              security       1.00      0.01      0.02       119\n",
            "              military       0.78      0.03      0.06       227\n",
            "           child_alone       0.00      0.00      0.00         0\n",
            "                 water       0.89      0.26      0.40       390\n",
            "                  food       0.86      0.40      0.55       744\n",
            "               shelter       0.89      0.24      0.38       596\n",
            "              clothing       0.75      0.03      0.07        86\n",
            "                 money       0.25      0.01      0.01       163\n",
            "        missing_people       0.00      0.00      0.00        69\n",
            "              refugees       0.50      0.00      0.01       207\n",
            "                 death       0.91      0.11      0.20       283\n",
            "             other_aid       0.69      0.02      0.04       870\n",
            "infrastructure_related       0.33      0.00      0.00       422\n",
            "             transport       0.67      0.04      0.07       303\n",
            "             buildings       0.71      0.06      0.11       336\n",
            "           electricity       1.00      0.02      0.05       130\n",
            "                 tools       0.00      0.00      0.00        33\n",
            "             hospitals       0.00      0.00      0.00        78\n",
            "                 shops       0.00      0.00      0.00        28\n",
            "           aid_centers       0.00      0.00      0.00        81\n",
            "  other_infrastructure       0.00      0.00      0.00       283\n",
            "       weather_related       0.88      0.62      0.72      1844\n",
            "                floods       0.92      0.29      0.44       550\n",
            "                 storm       0.80      0.34      0.47       605\n",
            "                  fire       0.00      0.00      0.00        64\n",
            "            earthquake       0.92      0.73      0.81       645\n",
            "                  cold       0.83      0.03      0.07       143\n",
            "         other_weather       0.67      0.02      0.03       338\n",
            "         direct_report       0.82      0.32      0.46      1256\n",
            "\n",
            "             micro avg       0.82      0.48      0.61     20755\n",
            "             macro avg       0.57      0.16      0.20     20755\n",
            "          weighted avg       0.77      0.48      0.53     20755\n",
            "           samples avg       0.70      0.46      0.51     20755\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIxMWEUvBlkI",
        "colab_type": "text"
      },
      "source": [
        "### 8. Try improving your model further. Here are a few ideas:\n",
        "* try other machine learning algorithms\n",
        "* add other features besides the TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1EY3JCRBlkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vector', CountVectorizer(tokenizer=tokenize)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "     ('clf', MultiOutputClassifier(\n",
        "        AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1, class_weight='balanced'))\n",
        "    ))\n",
        "])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKQEkTmhBlkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9492d01-385b-49a9-f604-2ab1d1afacdb"
      },
      "source": [
        "parameters ={\n",
        "        'clf__estimator__learning_rate': [0.2, 0.3],\n",
        "    }\n",
        "\n",
        "pipeline.get_params()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf': MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                                                    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                                                          class_weight='balanced',\n",
              "                                                                                          criterion='gini',\n",
              "                                                                                          max_depth=1,\n",
              "                                                                                          max_features=None,\n",
              "                                                                                          max_leaf_nodes=None,\n",
              "                                                                                          min_impurity_decrease=0.0,\n",
              "                                                                                          min_impurity_split=None,\n",
              "                                                                                          min_samples_leaf=1,\n",
              "                                                                                          min_samples_split=2,\n",
              "                                                                                          min_weight_fraction_leaf=0.0,\n",
              "                                                                                          presort='deprecated',\n",
              "                                                                                          random_state=None,\n",
              "                                                                                          splitter='best'),\n",
              "                                                    learning_rate=1.0,\n",
              "                                                    n_estimators=50,\n",
              "                                                    random_state=None),\n",
              "                       n_jobs=None),\n",
              " 'clf__estimator': AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                          class_weight='balanced',\n",
              "                                                          criterion='gini',\n",
              "                                                          max_depth=1,\n",
              "                                                          max_features=None,\n",
              "                                                          max_leaf_nodes=None,\n",
              "                                                          min_impurity_decrease=0.0,\n",
              "                                                          min_impurity_split=None,\n",
              "                                                          min_samples_leaf=1,\n",
              "                                                          min_samples_split=2,\n",
              "                                                          min_weight_fraction_leaf=0.0,\n",
              "                                                          presort='deprecated',\n",
              "                                                          random_state=None,\n",
              "                                                          splitter='best'),\n",
              "                    learning_rate=1.0, n_estimators=50, random_state=None),\n",
              " 'clf__estimator__algorithm': 'SAMME.R',\n",
              " 'clf__estimator__base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
              "                        max_depth=1, max_features=None, max_leaf_nodes=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                        random_state=None, splitter='best'),\n",
              " 'clf__estimator__base_estimator__ccp_alpha': 0.0,\n",
              " 'clf__estimator__base_estimator__class_weight': 'balanced',\n",
              " 'clf__estimator__base_estimator__criterion': 'gini',\n",
              " 'clf__estimator__base_estimator__max_depth': 1,\n",
              " 'clf__estimator__base_estimator__max_features': None,\n",
              " 'clf__estimator__base_estimator__max_leaf_nodes': None,\n",
              " 'clf__estimator__base_estimator__min_impurity_decrease': 0.0,\n",
              " 'clf__estimator__base_estimator__min_impurity_split': None,\n",
              " 'clf__estimator__base_estimator__min_samples_leaf': 1,\n",
              " 'clf__estimator__base_estimator__min_samples_split': 2,\n",
              " 'clf__estimator__base_estimator__min_weight_fraction_leaf': 0.0,\n",
              " 'clf__estimator__base_estimator__presort': 'deprecated',\n",
              " 'clf__estimator__base_estimator__random_state': None,\n",
              " 'clf__estimator__base_estimator__splitter': 'best',\n",
              " 'clf__estimator__learning_rate': 1.0,\n",
              " 'clf__estimator__n_estimators': 50,\n",
              " 'clf__estimator__random_state': None,\n",
              " 'clf__n_jobs': None,\n",
              " 'memory': None,\n",
              " 'steps': [('vector',\n",
              "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                   tokenizer=<function tokenize at 0x7f21365e0048>,\n",
              "                   vocabulary=None)),\n",
              "  ('tfidf',\n",
              "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
              "  ('clf',\n",
              "   MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                                                      base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                                                            class_weight='balanced',\n",
              "                                                                                            criterion='gini',\n",
              "                                                                                            max_depth=1,\n",
              "                                                                                            max_features=None,\n",
              "                                                                                            max_leaf_nodes=None,\n",
              "                                                                                            min_impurity_decrease=0.0,\n",
              "                                                                                            min_impurity_split=None,\n",
              "                                                                                            min_samples_leaf=1,\n",
              "                                                                                            min_samples_split=2,\n",
              "                                                                                            min_weight_fraction_leaf=0.0,\n",
              "                                                                                            presort='deprecated',\n",
              "                                                                                            random_state=None,\n",
              "                                                                                            splitter='best'),\n",
              "                                                      learning_rate=1.0,\n",
              "                                                      n_estimators=50,\n",
              "                                                      random_state=None),\n",
              "                         n_jobs=None))],\n",
              " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
              " 'tfidf__norm': 'l2',\n",
              " 'tfidf__smooth_idf': True,\n",
              " 'tfidf__sublinear_tf': False,\n",
              " 'tfidf__use_idf': True,\n",
              " 'vector': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                 tokenizer=<function tokenize at 0x7f21365e0048>,\n",
              "                 vocabulary=None),\n",
              " 'vector__analyzer': 'word',\n",
              " 'vector__binary': False,\n",
              " 'vector__decode_error': 'strict',\n",
              " 'vector__dtype': numpy.int64,\n",
              " 'vector__encoding': 'utf-8',\n",
              " 'vector__input': 'content',\n",
              " 'vector__lowercase': True,\n",
              " 'vector__max_df': 1.0,\n",
              " 'vector__max_features': None,\n",
              " 'vector__min_df': 1,\n",
              " 'vector__ngram_range': (1, 1),\n",
              " 'vector__preprocessor': None,\n",
              " 'vector__stop_words': None,\n",
              " 'vector__strip_accents': None,\n",
              " 'vector__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'vector__tokenizer': <function __main__.tokenize>,\n",
              " 'vector__vocabulary': None,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qz2Dpr4BlkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=3,verbose = 3)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKC-9m30BlkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "714df10f-318b-4b3f-cc26-164c1557a9ae"
      },
      "source": [
        "cv.fit(X_train, y_train)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vector',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preprocessor=None,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_accents=None,\n",
              "                                                        token_pattern='(?...\n",
              "                                                                                                                                 min_samples_split=2,\n",
              "                                                                                                                                 min_weight_fraction_leaf=0.0,\n",
              "                                                                                                                                 presort='deprecated',\n",
              "                                                                                                                                 random_state=None,\n",
              "                                                                                                                                 splitter='best'),\n",
              "                                                                                           learning_rate=1.0,\n",
              "                                                                                           n_estimators=50,\n",
              "                                                                                           random_state=None),\n",
              "                                                              n_jobs=None))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'clf__estimator__learning_rate': [0.2, 0.3]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CPhqJ5OBlkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = cv.predict(X_test)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UgJNydJBlkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "3801661d-af72-4b55-c2f8-31dcfb04cfc5"
      },
      "source": [
        "print(classification_report(y_test.values, y_predict, target_names=Y.columns.values))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "               related       0.92      0.63      0.75      4999\n",
            "               request       0.53      0.76      0.63      1093\n",
            "                 offer       0.01      0.37      0.03        38\n",
            "           aid_related       0.71      0.63      0.67      2708\n",
            "          medical_help       0.39      0.59      0.47       506\n",
            "      medical_products       0.23      0.69      0.35       333\n",
            "     search_and_rescue       0.12      0.49      0.19       185\n",
            "              security       0.04      0.54      0.07       119\n",
            "              military       0.33      0.71      0.45       227\n",
            "           child_alone       0.00      0.00      0.00         0\n",
            "                 water       0.55      0.88      0.67       390\n",
            "                  food       0.76      0.82      0.79       744\n",
            "               shelter       0.59      0.75      0.66       596\n",
            "              clothing       0.18      0.64      0.28        86\n",
            "                 money       0.26      0.72      0.38       163\n",
            "        missing_people       0.04      0.41      0.07        69\n",
            "              refugees       0.19      0.70      0.29       207\n",
            "                 death       0.38      0.76      0.50       283\n",
            "             other_aid       0.33      0.55      0.41       870\n",
            "infrastructure_related       0.13      0.57      0.21       422\n",
            "             transport       0.19      0.48      0.27       303\n",
            "             buildings       0.38      0.69      0.49       336\n",
            "           electricity       0.34      0.69      0.46       130\n",
            "                 tools       0.01      0.64      0.03        33\n",
            "             hospitals       0.10      0.50      0.17        78\n",
            "                 shops       0.01      0.36      0.02        28\n",
            "           aid_centers       0.08      0.54      0.13        81\n",
            "  other_infrastructure       0.10      0.65      0.17       283\n",
            "       weather_related       0.83      0.67      0.74      1844\n",
            "                floods       0.63      0.68      0.65       550\n",
            "                 storm       0.60      0.78      0.68       605\n",
            "                  fire       0.11      0.48      0.18        64\n",
            "            earthquake       0.89      0.80      0.84       645\n",
            "                  cold       0.34      0.66      0.45       143\n",
            "         other_weather       0.23      0.58      0.33       338\n",
            "         direct_report       0.52      0.70      0.60      1256\n",
            "\n",
            "             micro avg       0.39      0.66      0.49     20755\n",
            "             macro avg       0.33      0.61      0.39     20755\n",
            "          weighted avg       0.63      0.66      0.61     20755\n",
            "           samples avg       0.31      0.46      0.34     20755\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lKMBuB8Blke",
        "colab_type": "text"
      },
      "source": [
        "### 9. Export your model as a pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtT7f2W9Blke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_filepath = 'classifier.pickle'\n",
        "\n",
        "with open(model_filepath, 'wb') as model_file:\n",
        "        pickle.dump(model, model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-nPk-BABlkh",
        "colab_type": "text"
      },
      "source": [
        "### 10. Use this notebook to complete `train.py`\n",
        "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EriG5l1_Blki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}